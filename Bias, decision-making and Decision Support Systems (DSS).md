Automation Bias in Intelligent Time Critical Decision Support Systems
Cummings, M. (2004). Automation bias in intelligent time critical decision support systems. _AIAA 1st Intelligent Systems Technical Conference_. https://doi.org/10.2514/6.2004-6313
- Automation Bias - over reliance on decision support systems, causing the user to always think the computer is right.
- Has caused tragic accidents when people rely on technology too much for decision making
- Designers should be aware of the potential negative effects of increasing automation
- Future designs should aid human decisions, not totally replace decisions by humans
- May be important to note that decision technologies can also cause bias, in the process of eliminating bias.

Cognitive Biases in the use of Computer-Based Decision Support Systems
Arnott, D. (2005). Cognitive biases and decision support systems development: A design science approach. _Information Systems Journal_, _16_(1), 55–78. https://doi.org/10.1111/j.1365-2575.2006.00208.x
- Claims there needs to be more research in methods that could effectively limit biases in DSS
- Proposes 3 Debiasing techniques:
	 1) Correcting flaws in the experimental design surrounding the decision task
	 2) demonstrating to decision-makers that the biases exist and teaching them to avoid them.
	 3) correcting for possible mismatches between decision-maker and task
- Results showed that bias was present in computer based decision support systems, their approach to debiasing by making people aware of the bias had no effect.

Cognitive Biases and decision support systems development: a design science approach
Arnott, D. (2005). Cognitive biases and decision support systems development: A design science approach. _Information Systems Journal_, _16_(1), 55–78. https://doi.org/10.1111/j.1365-2575.2006.00208.x
- Paper reports a design science project  attempting to provide guidance for people developing DSS grounded i behavioral decision theory (theory of cognitive bias)
- Claims there as 37 types of bias
- Very long article, but contains lots of good research on how we could implement a DSS that
- One stage of their project is the  "construction of the design artefact: an evolutionary DSS development methodology that uses cognitive bias theory as a focusing construct, especially in its analysis cycles"

Mitigating cognitive bias with clinical decision support systems: an experimental study
Küper, A., Lodde, G., Livingstone, E., Schadendorf, D., & Krämer, N. (2023). Mitigating cognitive bias with clinical decision support systems: An experimental study. _Journal of Decision Systems_, 1–20. https://doi.org/10.1080/12460125.2023.2245215
- Clinical Decision Support Systems (CDSS) are used to help clinicians in their decision making by "providing targeted clinical knowledge, patient information and other relevant health information "
- Bias in clinical reasoning has been shown as a major source for diagnostic errors
- Proposes that a DSS that suggests possible diagnosis and provided info to mitigate cognitive bias could support doctors finding the correct diagnosis
- Crowley (2013) showed that technology could detect bias
- Found in their study that CDSS can mitigate availability bias and that it happens independently of the timing of support and medical experience of the users
- Neither Medical experience level or confidence level in the decision had a probability to change the estimate. 

Cognitive Bias, Decision Styles, and Risk Attitudes in decision making and DSS
Phillips-Wren, G., Power, D. J., & Mora, M. (2019). Cognitive bias, decision styles, and risk attitudes in decision making and DSS. _Journal of Decision Systems_, _28_(2), 63–66. https://doi.org/10.1080/12460125.2019.1646509
- Decision Support Systems (DSS) are supposed to help improve decisions by acquiring and processing data and using it to guide decision making.
- System should help user think more rationally
- People have bias in their decision making that can lead to poor or less optimal decisions
- DSS can help reinforce biases to make better decisions
- Two conditions that influence a decision aid
- Persons decision-making styles - the way in which people process and store info
- Decision makers attitude toward taking or avoiding risks - decisions involving risk imply that the most optimal outcome is not guaranteed.
- Discusses briefly 6 articles in which one said that there's weakness in current decision

Wearable Reasoner: Towards Enhanced Human Rationality Through A Wearable Device With An Explainable AI Assistant
https://dl.acm.org/doi/abs/10.1145/3384657.3384799 Overview:
- " Human judgments and decisions are prone to errors in reasoning caused by factors such as personal biases and external misinformation."
- "wearable reasoner" is a wearable system that is capable of analyzing if an argument is stated with evidence or not/
- results show it enhances rationality in users
- Is not directly related to bias, however states that improving error in reasoning is related to biases in perception. 

Augmented Human Mind: Case of Reasoning
https://hal.science/hal-02264940/document 
- A suggested "radical method to debiasing" using augmented reality. 
- "we made a first attempt to propose an approach of a system capable of augmenting the reasoning of his user."
- proposed system to to detect cognitive biases and change the environment as possibly with a smartphone or watch, HoloLens, etc. to modify the environment to debias situations. 

Addressing cognitive Biases in augmented Business Decision Systems
https://arxiv.org/abs/2009.08127
- How do algorithmic decision aids introduced in business decision processes affect task performance?
- Experiment to evaluate the effectiveness of presentation variants in reducing complacency bias. Results: found that optional presentation increases subjects' resistance to wrong recommendations. 
- "In the longer run, we envision that decision aids will be generalized in business decision systems, provided they are instrumented with tooling that continuously assesses their relevance and performance so as to mitigate risks while improving the productivity and quality of decision-making."

The Impact of Computer-Mediated Communications Systems on Biased Group Discussion. Hightower, Ross and Sayeed, Luftus. (1995). Computers in Human Behaviour. (11)1, 33-44. https://doi.org/10.1016/0747-5632(94)00019-E
- Study with ~90 undergraduates performed to examine the effects of communication mode (F2F vs. remote), information load, and distribution of information on biased discussion – the tendency for group members to spend more time and energy discussing information the group is already familiar with. They were tasked with settling on a hiring candidate through group discussion given information provided to individuals in the group. The amount of information shared between group individuals prior to discussion ranged from 33% to 60%. 90% of the groups chose the wrong candidate suggesting biased discussion occurred.
- Communication Mode – Results found CMCS discussions had >2x likelihood of resulting in biased discussion vs. the F2F counterpart.
- Information Distribution – Irrespective of communication mode, the greater the information distribution in the provided info to group members prior to group discussion, the greater the biased discussion. For groups with 60% distribution, the degree of biased discussion was more than twice that of 33% distribution.
- Information Load – It was not supported that higher information load will lead to greater discussion bias regardless of communication. This connection between information load and greater discussion bias was however supported for those groups required to communicate in CMCS vs. F2F. 

Understanding the role of computer-mediated counter-argument in countering confirmation bias. Hsieh-Hong Huang, Jack Shih-Chieh Hsu, Cheng-Yuan Ku. (2012). Decision Support Systems. (53). 438-447. https:/doi.org/10.1016/j.dss.2012.03.009. 
- It has long been established that confirmation bias can affect decision-making. The authors propose examination of a unique decisional characteristic – decision confidence – a subject’s beliefs about their decisional performance and their perception of the probability that their decisions are correct.
- The authors hypothesize that the presence of confirmation bias includes abnormally high decision confidence and inadequate adjustment of decisions. 
- They attempt to block or otherwise reduce confirmation bias through an ‘embedded de-bias function’ called computer mediated counter-argument. The DSS provides counter-argument according to the decision maker’s information reading behaviour.
- 241 subjects recruited from students enrolled in MBA programs at 7 universities. Divided into two groups – one with DSS counter-argument, the other without. They were given a stock investment task asking them to invest X amount between two companies with the decision process spanning an initial decision, exposure to a broad overview of relevant market data (that they would then sift through themselves), and a final decision. At each stage, their decision confidence and satisfaction with the process were measured.
- Findings included support for hypotheses claiming confirmation bias has less effect on both decision confidence and decision adjustment with computer-mediated counter-argument than for those without it, as well as subjects who use DSS with computer-mediated counter-argument will feel more satisfied with the decision-making outcome.

Mosier, K. L., Skitka, L. J., Heers, S., & Burdick, M. (1998). Automation Bias: Decision Making and Performance in High-Tech Cockpits. _The International Journal of Aviation Psychology_, _8_(1), 47–63. [https://doi.org/10.1207/s15327108ijap0801_3](https://doi.org/10.1207/s15327108ijap0801_3)
	- "**automation bias**, a recently documented factor in the use of automated aids and decision support systems. The term refers to **omission and commission errors resulting from the use of automated cues as a heuristic replacement for vigilant information seeking and processing.**"
	- Automation aids caused pilots to be less attentive to their decisions (including decisions made by aids), unless the pilot had taken steps to internalize a sense of accountability i.e. discipline for retracing their decision-making processes.
	- Interestingly, pilots who blindly followed false signals from their cognitive aid software later 'remembered' seeing corroborating signals with their own senses.
 
Skitka, L. J., Mosier, K. L., & Burdick, M. (1999). Does automation bias decision-making? _International Journal of Human-Computer Studies_, _51_(5), 991–1006. [https://doi.org/10.1006/ijhc.1999.0252](https://doi.org/10.1006/ijhc.1999.0252)
	- "Participants in non-automated settings out-performed their counterparts with a very but not perfectly reliable automated aid on a monitoring task. Participants with an aid made errors of omission (missed events when not explicitly prompted about them by the aid) and commission (did what an automated aid recommended, even when it contradicted their training and other 100% valid and available indicators)."
	- Same authors of previous article//very similar content
	- Contains more detail about omission errors, focusing on not-perfectly-reliable cognitive aids. If the aid fails to prompt the user about something it *should*, then the user is very likely to miss that error. Conversely, unlikely to make the same error of omission if there's no aid.
		- "Participants in the non-automated condition responded with 97% accuracy on the six omission error events, whereas participants in the automated condition responded with only a 59% accuracy rate on these same events. People with an AMA were therefore more likely to miss events than those without an AMA, if the AMA failed to notify them of the event." (p 1002)