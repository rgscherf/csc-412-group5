Tags: #DecisionSupportSystems

Mitigating cognitive bias with clinical decision support systems: an experimental study
Küper, A., Lodde, G., Livingstone, E., Schadendorf, D., & Krämer, N. (2023). Mitigating cognitive bias with clinical decision support systems: An experimental study. _Journal of Decision Systems_, 1–20. https://doi.org/10.1080/12460125.2023.2245215
- Clinical Decision Support Systems (CDSS) are used to help clinicians in their decision making by "providing targeted clinical knowledge, patient information and other relevant health information "
- Bias in clinical reasoning has been shown as a major source for diagnostic errors
- Proposes that a DSS that suggests possible diagnosis and provided info to mitigate cognitive bias could support doctors finding the correct diagnosis
- Crowley (2013) showed that technology could detect bias
- Found in their study that CDSS can mitigate availability bias and that it happens independently of the timing of support and medical experience of the users
- Neither Medical experience level or confidence level in the decision had a probability to change the estimate. 

Wearable Reasoner: Towards Enhanced Human Rationality Through A Wearable Device With An Explainable AI Assistant
https://dl.acm.org/doi/abs/10.1145/3384657.3384799 Overview:
- " Human judgments and decisions are prone to errors in reasoning caused by factors such as personal biases and external misinformation."
- "wearable reasoner" is a wearable system that is capable of analyzing if an argument is stated with evidence or not/
- results show it enhances rationality in users
- Is not directly related to bias, however states that improving error in reasoning is related to biases in perception. 

Addressing cognitive Biases in augmented Business Decision Systems
https://arxiv.org/abs/2009.08127
- How do algorithmic decision aids introduced in business decision processes affect task performance?
- Experiment to evaluate the effectiveness of presentation variants in reducing complacency bias. Results: found that optional presentation increases subjects' resistance to wrong recommendations. 
- "In the longer run, we envision that decision aids will be generalized in business decision systems, provided they are instrumented with tooling that continuously assesses their relevance and performance so as to mitigate risks while improving the productivity and quality of decision-making."

The Impact of Computer-Mediated Communications Systems on Biased Group Discussion. Hightower, Ross and Sayeed, Luftus. (1995). Computers in Human Behaviour. (11)1, 33-44. https://doi.org/10.1016/0747-5632(94)00019-E
- Study with ~90 undergraduates performed to examine the effects of communication mode (F2F vs. remote), information load, and distribution of information on biased discussion – the tendency for group members to spend more time and energy discussing information the group is already familiar with. They were tasked with settling on a hiring candidate through group discussion given information provided to individuals in the group. The amount of information shared between group individuals prior to discussion ranged from 33% to 60%. 90% of the groups chose the wrong candidate suggesting biased discussion occurred.
- Communication Mode – Results found CMCS discussions had >2x likelihood of resulting in biased discussion vs. the F2F counterpart.
- Information Distribution – Irrespective of communication mode, the greater the information distribution in the provided info to group members prior to group discussion, the greater the biased discussion. For groups with 60% distribution, the degree of biased discussion was more than twice that of 33% distribution.
- Information Load – It was not supported that higher information load will lead to greater discussion bias regardless of communication. This connection between information load and greater discussion bias was however supported for those groups required to communicate in CMCS vs. F2F. 

Understanding the role of computer-mediated counter-argument in countering confirmation bias. Hsieh-Hong Huang, Jack Shih-Chieh Hsu, Cheng-Yuan Ku. (2012). Decision Support Systems. (53). 438-447. https:/doi.org/10.1016/j.dss.2012.03.009. 
- It has long been established that confirmation bias can affect decision-making. The authors propose examination of a unique decisional characteristic – decision confidence – a subject’s beliefs about their decisional performance and their perception of the probability that their decisions are correct.
- The authors hypothesize that the presence of confirmation bias includes abnormally high decision confidence and inadequate adjustment of decisions. 
- They attempt to block or otherwise reduce confirmation bias through an ‘embedded de-bias function’ called computer mediated counter-argument. The DSS provides counter-argument according to the decision maker’s information reading behaviour.
- 241 subjects recruited from students enrolled in MBA programs at 7 universities. Divided into two groups – one with DSS counter-argument, the other without. They were given a stock investment task asking them to invest X amount between two companies with the decision process spanning an initial decision, exposure to a broad overview of relevant market data (that they would then sift through themselves), and a final decision. At each stage, their decision confidence and satisfaction with the process were measured.
- Findings included support for hypotheses claiming confirmation bias has less effect on both decision confidence and decision adjustment with computer-mediated counter-argument than for those without it, as well as subjects who use DSS with computer-mediated counter-argument will feel more satisfied with the decision-making outcome.
 
Skitka, L. J., Mosier, K. L., & Burdick, M. (1999). Does automation bias decision-making? _International Journal of Human-Computer Studies_, _51_(5), 991–1006. [https://doi.org/10.1006/ijhc.1999.0252](https://doi.org/10.1006/ijhc.1999.0252)
- "Participants in non-automated settings out-performed their counterparts with a very but not perfectly reliable automated aid on a monitoring task. Participants with an aid made errors of omission (missed events when not explicitly prompted about them by the aid) and commission (did what an automated aid recommended, even when it contradicted their training and other 100% valid and available indicators)."
- Same authors of previous article//very similar content
- Contains more detail about omission errors, focusing on not-perfectly-reliable cognitive aids. If the aid fails to prompt the user about something it *should*, then the user is very likely to miss that error. Conversely, unlikely to make the same error of omission if there's no aid.
- "Participants in the non-automated condition responded with 97% accuracy on the six omission error events, whereas participants in the automated condition responded with only a 59% accuracy rate on these same events. People with an AMA were therefore more likely to miss events than those without an AMA, if the AMA failed to notify them of the event." (p 1002)
