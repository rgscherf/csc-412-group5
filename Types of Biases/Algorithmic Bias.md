## The Bias in the Machine: Facial Recognition Technology and Racial Disparities 
### Sidney Perkowitz
Retrieved from: https://mit-serc.pubpub.org/pub/bias-in-machine/release/1?readingCollection=34db8026
- Growing research suggests FRTs are guilty of troubling levels of bias, particularly as these technologies are incorporated into law enforcement agencies. As we all struggle to contain these issues, the author claims that we can turn to older forensic technologies, such as fingerprint ID, for answers. 
- Fingerprint ID was prone to egregious errors as well, including it’s use to wrongfully ID suspects in the 2004 Madrid terrorist bombings of commuter trains.
- In 2009 and 2016 concerted efforts were made on the federal level to scrutinize this technology and implement overarching reforms to control the use fingerprint ID and confirm the veracity of the results.
- No such approaches have been implemented regarding facial recognition. Municipal law enforcement agencies are free to choose among scores of commercially available algorithms without clear guidance about their use or reliability.

## Algorithmic bias: review, synthesis, and future research directions
### Kordzadeh, N., & Ghasemaghaei, M
https://doi.org/10.1080/0960085X.2021.1927212
 - This is a lit review of research related to algorithmic bias. Studies were categorized under six themes:
 	1. Ethical, social, and philosophical considerations
 	2. Legal and regulatory implications (discussed [[Algorithmic Bias#The Bias in the Machine Facial Recognition Technology and Racial Disparities|here]])
 	3. Socio-technical design
 	4. Concerns, #perception, and needs
 	5. Antecedents of fairness #perception  (discussed [[Algorithmic Bias#Factors Influencing Perceived Fairness in Algorithmic Decision-Making Algorithm Outcomes, Development Procedures, and Individual Differences|here]])
 	6. Impacts of machine advice on decisions (discussed by Mosier et al [[Current Decision Support Systems for Mitigating Bias#Does automation bias decision-making?|here]] and [[Creation of Bias from DSS#Automation Bias Decision Making and Performance in High-Tech Cockpits|here]])
 - "algorithmic bias appears when _an algorithm distributes benefits and burdens unequally among different individuals or groups_." It's important to take a domain-specific approach because one measure of bias can mean a lot in one of the above themes, but have less real impact in another. 
 - The authors note that algorithmic bias has been canvassed exhaustively at the conceptual level, but little empirical work has been done. "Moreover, the mechanisms through which technology-driven biases translate into decisions and behaviors have been largely overlooked."
 - The article also highlights the difference between "algorithmic bias, as a computationally-measured construct, and perceived fairness, as a subjective construct."
   
## Factors Influencing Perceived Fairness in Algorithmic Decision-Making: Algorithm Outcomes, Development Procedures, and Individual Differences
### Wang, R., Harper, F. M., & Zhu, H.
https://doi.org/10.1145/3313831.3376813
- This study stresses that perceptions of fairness are highly complicated, nuanced, and ultimately subjective.
- The article examines which factors influence people’s #perception of the fairness of algorithmic decision-making processes.
- "We find that people’s evaluations of fairness are very sensitive to whether or not they receive a positive outcome personally, even surpassing the negative effect of describing an algorithm with strong biases against particular demographic groups."
